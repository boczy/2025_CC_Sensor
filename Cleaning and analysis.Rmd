---
title: "Data Cleaning and analysis"
author: "Chris Bocz"
date: "2025-04-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

## Load Data

```{r}
# List Raw Data files in the working directory (raw files from data-loggers are in .dat format).  Create a list of all files, then 2 seperate lists for files from Watkinsville vs Midville.

file_paths <- list.files(
  path = "Data/",
  pattern = "\\.dat$",
  full.names = TRUE
)
mdv_files <- file_paths[grepl("Midville", file_paths, ignore.case = TRUE)]
wat_files <- file_paths[grepl("Watkinsville", file_paths, ignore.case = TRUE)]

#Create data-frames, 1 for Midville, 1 for Watkinsville.  Add filename as a column, for extracting metdata later.  Skip first row of observations; standard for data files from our Campbell Scientific loggers 

mdv_df <- map_dfr(mdv_files, function(file) {
  df <- read_csv(file, skip = 1)  # Read file, skipping the first row
  df %>% mutate(source_file = basename(file))  # Add filename as a column
})

wat_df <- map_dfr(wat_files, function(file) {
  df <- read_csv(file, skip = 1)  # Read file, skipping the first row
  df %>% mutate(source_file = basename(file))  # Add filename as a column
})

```


## Clean Data
```{r Clean mdv data}

# Extract the units row
mdv_units_row <- mdv_df[1, ]

# Remove the units row and next row from the data
mdv_cleaned_data1 <- mdv_df[-c(1,2),]

# Combine column names and units
new_colnames <- paste0(names(mdv_cleaned_data1), " (", unlist(mdv_units_row), ")")
names(mdv_cleaned_data1) <- new_colnames
mdv_cleaned_data1 <- mdv_cleaned_data1 %>%
  rename(`source file` = `source_file (Cotton Commission Midville Early_Daily.dat)`)

# Remove un-needed columns
mdv_cleaned_data2 <- mdv_cleaned_data1 %>%
   select(-`RECORD (RN)`, -`BattV_Min (Volts)`, -`PTemp_C_Avg (Deg C)`, -`BattV_Avg (NA)`)

# Remove duplicate/missing data, convert column names to lower-case, replace spaces with underscores.  This is general practice to standardize column names and make them universally readable to Tinyverse
mdv_cleaned_data3 <- mdv_cleaned_data2 %>%
  na.omit() %>%  # Remove rows with missing values
  distinct() %>%  # Remove duplicate rows
  rename_all(tolower) %>%  # Convert column names to lowercase
  rename_all(~gsub(" ", "_", .))  # Replace spaces with underscores

# Convert the original timestamp column to date-time format and rename it, remove timestamp_(ts) column
mdv_cleaned_data4 <- mdv_cleaned_data3 %>%
  mutate(timestamp = ymd_hms(`timestamp_(ts)`)) %>%
  select(-`timestamp_(ts)`, everything())

#Remove NA's introduced in the last step:
mdv_cleaned_data5 <- na.omit(mdv_cleaned_data4)

## Filter the dataset to remove observations before sensors were installed and after sensors were pulled (October 11, 2024 in Midville, November 11, 2024 in Watkinsville)  
mdv_cleaned_data6 <- mdv_cleaned_data5 %>%
  filter(timestamp <= as.POSIXct("2024-10-11 23:59:59"))

# Pivot to long data, make sensor depth, cover-crop treatment and "stat" into variables. Stat: loggers took min, max, and avg data for each observation, the "stat" column tells us which of those is being reported.  Also pull metadata from filenames (sourcefile column), create cc_plant_time (early vs late planted cover crop), and dara_freq (whether observation is hourly or daily)

mdv_cleaned_data7 <- mdv_cleaned_data6 %>%
  pivot_longer(
    cols = -c(timestamp, source_file),
    names_to = c("measure", "treatment", "depth", "stat", "units"),
    names_sep = "_"
  ) %>%
  mutate(
    # Extract metadata from source_file
    cc_plant_time = str_extract(source_file, "Early|Late") %>% tolower(),
    data_freq = str_extract(source_file, "Daily|Hourly") %>% tolower(),
  
    # Handle measure units
    measure_units = case_when(
     measure == "t" & units == "(deg" ~ "t_(deg_c)",
      TRUE ~ paste0(measure, "_", units)
    ),
    value = as.numeric(value)
  )%>%
  select(-measure, -units) %>%
  filter(!is.na(measure_units)) #%>%
  # Rename and format columns
  #rename_with(~ tolower(gsub(" ", "_", .x)))  # Applies to all columns

  #select(-measure, -units) %>%
  #filter(!is.na(measure_units))  # Remove rows where measure_units is NA

#Remove source_file column
mdv_cleaned_data8 <- mdv_cleaned_data7 %>% 
  select(-source_file)

#Pivot the data so that measure_units becomes columns, means a seperate column for each collected-data variable
mdv_cleaned_data9 <- mdv_cleaned_data8 %>%
  pivot_wider(names_from = measure_units, values_from = value) %>% 
  select(-timestamp_NA)#remove uneeded column created by pivot_wider

# Remove observations where `vwc_(m^3/m^3)` <= 0.0000 or `ec_(ds/m)` < 0.  This should remove observations where loggers were on but not installed.  Remove NAs.
mdv_cleaned_data10 <- mdv_cleaned_data9 %>%
  filter(!(`vwc_(m^3/m^3)` <= 0 | `ec_(ds/m)` < 0)) %>% 
  na.omit()

```

## Data Analysis

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
